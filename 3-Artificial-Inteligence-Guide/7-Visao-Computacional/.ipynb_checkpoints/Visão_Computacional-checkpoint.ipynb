{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/viannaandreBR/My-Data-Science-Journey/blob/main/Vis%C3%A3o_Computacional.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-DeXKmcjLl89"
   },
   "source": [
    "# Visão computacional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w8zOtNhKLp-Z"
   },
   "source": [
    "## Detecção de faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Dtqej-kXM-ay"
   },
   "outputs": [],
   "source": [
    "import cv2 # OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python3 -c \"import cv2; print(cv2.__version__)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fXwS3AKTNYYq"
   },
   "outputs": [],
   "source": [
    "imagem = cv2.imread('/content/workplace-1245776_1920.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(imagem) #not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.4-dev) /tmp/pip-req-build-h45n7_hz/opencv/modules/highgui/src/window.cpp:1006: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6189/2575251051.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/workplace-1245776_1920.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mwindow_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'image'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.4-dev) /tmp/pip-req-build-h45n7_hz/opencv/modules/highgui/src/window.cpp:1006: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('/content/workplace-1245776_1920.jpg', 0)\n",
    "window_name = 'image'\n",
    "cv2.imshow(window_name, img)\n",
    "cv2.waitKey(5000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.4-dev) :-1: error: (-5:Bad argument) in function 'imshow'\n> Overload resolution failed:\n>  - imshow() missing required argument 'mat' (pos 2)\n>  - imshow() missing required argument 'mat' (pos 2)\n>  - imshow() missing required argument 'mat' (pos 2)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6189/2686445785.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimagem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.4-dev) :-1: error: (-5:Bad argument) in function 'imshow'\n> Overload resolution failed:\n>  - imshow() missing required argument 'mat' (pos 2)\n>  - imshow() missing required argument 'mat' (pos 2)\n>  - imshow() missing required argument 'mat' (pos 2)\n"
     ]
    }
   ],
   "source": [
    "cv2.imshow(imagem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 724
    },
    "id": "e5DIoPIJNeTv",
    "outputId": "d1846f1a-e03d-4754-ac0a-c1163ce90b34"
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.4-dev) /tmp/pip-req-build-h45n7_hz/opencv/modules/highgui/src/window.cpp:1006: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6189/2386244976.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#from google.colab.patches import cv2_imshow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#cv2_imshow(imagem)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ImageWindow'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimagem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.4-dev) /tmp/pip-req-build-h45n7_hz/opencv/modules/highgui/src/window.cpp:1006: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\n"
     ]
    }
   ],
   "source": [
    "#cv2_imshow(imagem)\n",
    "#from google.colab.patches import cv2_imshow\n",
    "#cv2_imshow(imagem)\n",
    "cv2.imshow('ImageWindow',imagem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9yqexKWROVYC"
   },
   "outputs": [],
   "source": [
    "detector_face = cv2.CascadeClassifier('/content/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 724
    },
    "id": "jg2Rf8B4Oc3K",
    "outputId": "cc3bb280-0e3a-47b0-efef-a9b2526252ab"
   },
   "outputs": [],
   "source": [
    "imagem_cinza = cv2.cvtColor(imagem, cv2.COLOR_BGR2GRAY)\n",
    "cv2_imshow(imagem_cinza)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QXw27smvO53r"
   },
   "outputs": [],
   "source": [
    "deteccoes = detector_face.detectMultiScale(imagem_cinza, scaleFactor=1.3, minSize=(30,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "id": "Dpp0uLq_PDZW",
    "outputId": "03fe9fd5-a780-477b-ed90-da62aa221e67"
   },
   "outputs": [],
   "source": [
    "deteccoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "id": "l94uzkQBPH8d",
    "outputId": "01f71d1e-96b2-4799-cea9-41f22dcb2124"
   },
   "outputs": [],
   "source": [
    "len(deteccoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 724
    },
    "id": "6hKnWLQfPyvX",
    "outputId": "d85b04ce-b1f6-4271-917b-023dbfa5672c"
   },
   "outputs": [],
   "source": [
    "for (x, y, l, a) in deteccoes:\n",
    "  #print(x, y, l, a)\n",
    "  cv2.rectangle(imagem, (x, y), (x + l, y + a), (0,255,0), 2)\n",
    "cv2_imshow(imagem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZOW43rIEPJg5"
   },
   "source": [
    "## Detecção do corpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "id": "hSEHWX21Bs5i",
    "outputId": "19ce9b2d-c4ab-4097-acbb-6ee99e5fd391"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('/content/pessoas.jpg')\n",
    "#cv2_imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "VuSlHj5RBwV_",
    "outputId": "f21996fa-bd2f-479f-9bac-48bbbfd32a38"
   },
   "outputs": [],
   "source": [
    "detector_corpo = cv2.CascadeClassifier('/content/fullbody.xml')\n",
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "detections = detector_corpo.detectMultiScale(image_gray, scaleFactor=1.1, minSize=(50,50))\n",
    "print(len(detections))\n",
    "print(detections)\n",
    "for (x, y, l, a) in detections:\n",
    "  cv2.rectangle(image, (x, y), (x + l, y + a), (0,255,0), 2)\n",
    "cv2_imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AEIUhRMmT76n"
   },
   "source": [
    "## Reconhecimento facial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pIVSM0E0gNHK"
   },
   "source": [
    "### Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yCuRTW_2D2G0"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "id": "inB1ByBzD8Uw",
    "outputId": "b38e913d-012a-4276-e61f-46d695bcf019"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_MhPsuXaETAP"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "path = '/content/drive/My Drive/Cursos - recursos/yalefaces.zip'\n",
    "zip_object = zipfile.ZipFile(file=path, mode='r')\n",
    "zip_object.extractall('./')\n",
    "zip_object.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RLK0221XGSpz"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir('/content/yalefaces/treinamento')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cVKq95aEF-Gs"
   },
   "outputs": [],
   "source": [
    "def dados_imagem():\n",
    "  caminhos = [os.path.join('/content/yalefaces/treinamento', f) for f in os.listdir('/content/yalefaces/treinamento')]\n",
    "  faces = []\n",
    "  ids = []\n",
    "  for caminho in caminhos:\n",
    "    if caminho == '/content/yalefaces/treinamento/.ipynb_checkpoints':\n",
    "      continue\n",
    "    imagem = Image.open(caminho).convert('L')\n",
    "    imagem_np = np.array(imagem, 'uint8')\n",
    "    id = int(os.path.split(caminho)[1].split('.')[0].replace('subject', ''))\n",
    "    ids.append(id)\n",
    "    faces.append(imagem_np)\n",
    "  return np.array(ids), faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ks8tnULYHmZ2"
   },
   "outputs": [],
   "source": [
    "ids, faces = dados_imagem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "q1txYTi6I_NK",
    "outputId": "b45bfe4a-1114-42a0-a9f5-d28dbafcb174"
   },
   "outputs": [],
   "source": [
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160
    },
    "id": "N7Rs0ECZJEgY",
    "outputId": "fab9861a-459f-4df3-eb95-4f786ef97639"
   },
   "outputs": [],
   "source": [
    "print(faces[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_kt50ypTJVC2"
   },
   "outputs": [],
   "source": [
    "lbph = cv2.face.LBPHFaceRecognizer_create()\n",
    "lbph.train(faces, ids)\n",
    "lbph.write('classificadorLBPH.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5VeP4wBCgS5x"
   },
   "source": [
    "### Classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kPi6n9M4J6Kv"
   },
   "outputs": [],
   "source": [
    "reconhecedor = cv2.face.LBPHFaceRecognizer_create()\n",
    "reconhecedor.read('/content/classificadorLBPH.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N_B23UJHKOG0"
   },
   "outputs": [],
   "source": [
    "imagem_teste = '/content/yalefaces/teste/subject10.sad.gif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160
    },
    "id": "mDwEGJICKUo_",
    "outputId": "7d87b4bf-1878-4606-ff3f-9f145e2353ce"
   },
   "outputs": [],
   "source": [
    "imagem = Image.open(imagem_teste).convert('L')\n",
    "imagem_np = np.array(imagem, 'uint8')\n",
    "print(imagem_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "id": "MBP_EwU-Kkcj",
    "outputId": "7890106b-c6f0-41e6-c4e2-52344f55275e"
   },
   "outputs": [],
   "source": [
    "idprevisto, _ = reconhecedor.predict(imagem_np)\n",
    "idprevisto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "id": "Pkvo_ZdqK3kz",
    "outputId": "9a7c88b7-7a1c-4fb1-c28b-77abea569993"
   },
   "outputs": [],
   "source": [
    "idcorreto = int(os.path.split(imagem_teste)[1].split('.')[0].replace('subject', ''))\n",
    "idcorreto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "BYGejzQqLG6_",
    "outputId": "03a4d9f1-a037-4f4b-e9fc-c266fc299c4a"
   },
   "outputs": [],
   "source": [
    "cv2.putText(imagem_np, 'P: ' + str(idprevisto), (x,y + 30), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,255,0))\n",
    "cv2.putText(imagem_np, 'C: ' + str(idcorreto), (x,y + 50), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,255,0))\n",
    "cv2_imshow(imagem_np)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Visão Computacional.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
